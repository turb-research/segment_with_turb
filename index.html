<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title> Dynamic Object Segmentation in Turbulence (DOST) Dataset </title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
<!--             <h1 class="title is-1 publication-title"> Dynamic Object Segmentation in Turbulence (DOST) Dataset </h1> -->
            <h1 class="title is-1 publication-title"> Unsupervised Moving Object Segmentation with Atmospheric Turbulence </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/dehao-qin/?locale=en_US" target="_blank"><sup>1</sup>Dehao Qin</a>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/riponsaha/" target="_blank"><sup>2</sup>Ripon Saha</a>,</span>
                  <span class="author-block">
                  <a href="https://www.linkedin.com/in/woojehchung/" target="_blank"><sup>2</sup>Woojeh Chung</a>,</span>
                  <span class="author-block">
                    <a href="https://cs.gmu.edu/~jinweiye/" target="_blank"><sup>3</sup>Jinwei Ye</a>,</span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/suren-jayasuriya-4112926b/" target="_blank"><sup>2</sup>Suren Jayasuriya</a>,</span>
                  <span class="author-block">
                    <a href="https://nianyil.people.clemson.edu/" target="_blank"><sup>1</sup>Nianyi Li</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Clemson University,<br></span>
                    <span class="author-block"><sup>2</sup>Arizona State University,<br></span>
                    <span class="author-block"><sup>3</sup>George Mason University<br></span>
<!--                     <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2311.03572" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
<!--                     <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/turb-research/Unsupervised-Moving-Object-Segmentation-with-Atmospheric-Turbulence" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                 <!-- Dataset -->


                  <span class="link-block">
                      <a href="https://turb-research.github.io/DOST/" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon" style="vertical-align: middle; font-size: 20px;">&#129303;</span>
                          <span style="vertical-align: middle;">Dataset</span>
                      </a>
                  </span>                         

                
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/eccv.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Comparison with SOTA.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Paper abstract</h2>
        <div class="content has-text-justified">
          <p>
            Moving object segmentation in the presence of atmospheric
turbulence is highly challenging due to turbulence-induced irregular and
time-varying distortions. In this paper, we present an unsupervised approach for segmenting moving objects in videos downgraded by atmospheric turbulence. Our key approach is to adopt a detect-then-grow
scheme: we first identify a small set of pixels that belong to moving
objects with high confidence, then gradually grow a foreground mask
from those seeds that segment all moving objects in the scene. In order
to disentangle different types of motions, we check the rigid geometric
consistency among video frames. We then use the Sampson distance to
initialize the seedling pixels. After growing per-frame foreground masks,
we use spatial grouping loss and temporal consistency loss to further refine the masks in order to ensure their spatio-temporal consistency. Our
method is unsupervised and does not require training on labeled data.
For validation, we collect and release the first real-captured long-range
turbulent video dataset with ground truth masks for moving objects.
We evaluate our method both qualitatively and quantitatively on our
real dataset. Results show that our method achieves good accuracy in
segmenting moving objects and is robust for long-range videos with various turbulence strengths.

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- pipeline -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pipeline</h2>
        <div class="content has-text-justified">
          <img src="static/images/pipe.jpg" alt="MY ALT TEXT"/>

          <p>
            Our method starts with calculating bidirectional optical flow. To disentangle
actual object motion from turbulent motion, we use a novel epipolar geometry-based consistency check to generate motion feature maps that only preserve
object motions. We then adopt a region-growing scheme that generates per-object motion segmentation masks from a small set of seed pixels. Finally, we
develop a U-Net trained by our proposed bidirectional consistency losses
and a pixel grouping function to improve the spatio-temporal consistency of
estimated motion segmentation masks

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- epi -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motion disentanglement</h2>
        <div class="content has-text-justified">
          <img src="static/images/epi.jpg" alt="MY ALT TEXT"/>

          <p>
            We first tackle the problem of motion disentanglement, which is a major challenge posed by turbulence perturbation in rigid motion analysis. Our key idea
is to check on the rigid geometric consistency among video frames: pixels on
moving objects do not obey the geometric consistency constraint posed by the
image formation model. Specifcially, we use the Sampson distance, which measures geometric consistency with a given epipolar geometry, to improve the
spatial-temporal consistency among video frames. We first average the optical flow between adjacent frames to stabilize the direct estimations, since
they are susceptible to turbulence perturbation. We then calculate the Sampson distance using fundamental matrices estimated from the averaged optical
flow. Next, we merge the Sampson distance maps as the motion feature maps
{Mt|t = 1, 2, . . . , T }. We use the motion feature map values as indicators of how
likely a pixel has rigid motion (the higher the value, the higher the likelihood).

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- result -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Quantitative comparisons result</h2>
        <div class="content has-text-justified">
          <img src="static/images/score.png" alt="MY ALT TEXT"/>

          <p>
            We organize videos into two sets, “normal turb.” and “severe turb.”, according to their exhibited turbulence strength. Our method significantly outperforms these state-of-the-art on
motion segmentation accuracy under various turbulence strengths. In normal
cases, some can still achieve decent performance, whereas our method scores
much higher in all metrics. Compared to TMO, whose overall score is the highest among the three state-of-the-art, our accuracy is increasing by 60.1% in J
and 34.9% in F. In severe cases, the performance of all state-of-the-art significantly downgrades, with all J values lower than 0.25 and F lower than 0.35. In
contrast, our method is relatively robust to strong turbulence.

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



  
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/00013.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Dataset example.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->











<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{qin2024unsupervised,
  title={Unsupervised Object Segmentation for Video With Atmospheric Turbulence},
  author={Qin, Dehao and Saha, Ripon Kumar and Chung, Woojeh and Ye, Jinwei and Jayasuriya, Suren and Li, Nianyi},
  booktitle={European Conference on Computer Vision},
  year={2024},
  organization={Springer}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<!--   <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
